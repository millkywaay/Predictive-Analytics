# -*- coding: utf-8 -*-
"""Submission 1 ML Terapan - Khoirunnisa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UdaWokK9A-9zeNA46ESkpMRO3uyFsinj

# **Khoirunnisa - MC009D5X2406**

# **1. Import libray**

Mingimport semua libray yang akan dibutuhkan dalam case ini
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.inspection import PartialDependenceDisplay

"""# **2. Data understanding**

Analisis data dilakukan melalui beberapa tahapan untuk mengidentifikasi insight dan masalah yang perlu ditangani, meliputi:

1. Pemeriksaan Struktur Data (df.info()) - Memverifikasi tipe data dan format dataset
2. Analisis Statistik Deskriptif (df.describe()) - Menilai distribusi dan karakteristik numerik
3. Validasi Data Unik (df.nunique()) - Memastikan konsistensi nilai kategori
4. Deteksi Data Hilang - Mengidentifikasi missing values yang perlu penanganan
5. Pemeriksaan Duplikat - Menemukan dan menangani record yang identik
6. Identifikasi Outlier - Mendeteksi nilai ekstrim yang mungkin mengganggu analisis
7. Eksplorasi Data - Melalui analisis univariat (per variabel) dan multivariat (hubungan antar variabel)

## 2.1 Data loading
"""

df = pd.read_csv('https://raw.githubusercontent.com/millkywaay/Dataset-Coding-Camp/refs/heads/main/Machine%20Learning%20Pemula/Mental%20health/mentalhealth_dataset.csv')
df.head()

"""## 2.2 Exploratory Data Analysis (EDA)"""

df.info()

"""Dataset memiliki 15 kolom, dengan jumlah data 1000 baris data"""

df.describe()

"""Analisis statistik menggunakan describe() menunjukkan data numerik terdistribusi dengan baik, ditandai dengan nilai mean dan median yang seimbang serta penyebaran data yang simetris di sekitar nilai tengah, tanpa ditemukan adanya outlier yang signifikan"""

df.nunique()

categorical_cols = df.select_dtypes(include=['object']).columns

for col in categorical_cols:
    unique_values = df[col].unique()
    unique_count = df[col].nunique()
    print(f"\nKolom: {col}")
    print(f"Jumlah unik: {unique_count}")
    print(f"Nilai unik: {sorted(unique_values)}")
    print("Contoh distribusi:")
    print(df[col].value_counts().head())

"""Terdapat inkonsistensi data pada kolom Course dan Years of Study, misalnya penulisan "BENL" dan "benl" yang sebenarnya merujuk pada hal yang sama. Perbedaan dalam penggunaan huruf kapital/kecil menyebabkan sistem menganggapnya sebagai nilai yang berbeda sehinga perlu penanganan lebih lanjut dengan merubah value ke format yang sesuai."""

df['Course'] = df['Course'].str.strip().str.title()

course_mapping = {
    'Accounting': 'Accounting',
    'Bcs': 'BCS',
    'Bit': 'BIT',
    'Benl': 'BENL',
    'Biomedical Science': 'Biomedical Science',
    'Biotechnology': 'Biotechnology',
    'Business Administration': 'Business Administration',
    'Cts': 'CTS',
    'Communication': 'Communication',
    'Diploma Tesl': 'TESL',
    'Diploma Nursing': 'Nursing',
    'Econs': 'Economics',
    'Engin': 'Engineering',
    'Engine': 'Engineering',
    'Engineering': 'Engineering',
    'Fiqh': 'Fiqh',
    'Fiqh Fatwa': 'Fiqh',
    'Human Resources': 'Human Resources',
    'Human Sciences': 'Human Sciences',
    'It': 'IT',
    'Irkhs': 'IRKHS',
    'Islamic Education': 'Islamic Education',
    'Kenms': 'KENMS',
    'Kirkhs': 'KIRKHS',
    'Koe': 'KOE',
    'Kop': 'KOP',
    'Law': 'Law',
    'Laws': 'Law',
    'Malcom': 'MALCOM',
    'Marine Science': 'Marine Science',
    'Mathemathics': 'Mathematics',
    'Mathematics': 'Mathematics',
    'Mhsc': 'MHSC',
    'Nursing': 'Nursing',
    'Pendidikan Islam': 'Islamic Education',
    'Psychology': 'Psychology',
    'Radiography': 'Radiography',
    'Taasl': 'TAASL',
    'Usuluddin': 'Usuluddin'
}

df['Course'] = df['Course'].replace(course_mapping)

df['YearOfStudy'] = df['YearOfStudy'].str.strip().str.lower()

year_mapping = {
    'year 1': 'year 1',
    'year 2': 'year 2',
    'year 3': 'year 3',
}
df['YearOfStudy'] = df['YearOfStudy'].replace(year_mapping)

df.to_csv('cleaned_dataset.csv', index=False)

df = pd.read_csv('cleaned_dataset.csv')
df.head()

print("Unique Course:", df['Course'].nunique())
print(df['Course'].value_counts())

print("\nUnique YearOfStudy:", df['YearOfStudy'].nunique())
print(df['YearOfStudy'].value_counts())

"""Nilai unik yang tidak konsisten telah diperbaiki, sehingga terjadi penurunan jumlah kategori. Kolom Course yang sebelumnya memiliki 49 nilai unik kini menjadi 35 setelah standarisasi. Demikian pula, kolom Year of Study yang awalnya memiliki 7 variasi kini telah dirapikan menjadi hanya 4 kategori. Proses ini dilakukan untuk memastikan data lebih bersih dan konsisten, sehingga analisis selanjutnya dapat dilakukan secara lebih akurat dan menghasilkan nilai yang valid.

### 2.2.1 Cek missing value
"""

df.isna().sum()

"""Dataset sudah cukup bersih karena tidak mengadung missing value

### 2.2.2 Cek data duplikat
"""

duplicate = df.duplicated().sum()
print("Jumlah data duplikast : ", duplicate)

"""Tidak data duplikat

### 2.2.3 Cek data outlier
"""

numeric_cols = df.select_dtypes(include=[np.number]).columns

plt.figure(figsize=(12, 10))
sns.boxplot(data=df[numeric_cols])
plt.xticks(rotation=90)
plt.title('Boxplot untuk Deteksi Outlier')
plt.show()

Q1 = df[numeric_cols].quantile(0.25)
Q3 = df[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = ((df[numeric_cols] < lower_bound) | (df[numeric_cols] > upper_bound))
print("Jumlah outlier per kolom:")
print(outliers.sum())

df['SpecialistTreatment'].value_counts()

df['HasMentalHealthSupport'].value_counts()

"""Jika dilihat menggunakan boxplot, kolom `SpecialistTreatment` dan `HasMentalHealthSupport` tidak menunjukkan adanya outlier. Namun ketika dilakukan pengecekan menggunakan metode IQR, teridentifikasi 67 outlier pada kedua kolom tersebut. Setelah dianalisis lebih lanjut, nilai yang terdeteksi sebagai outlier ini sebenarnya bukan true outlier, melainkan nilai minoritas dalam distribusi data yang sangat tidak seimbang (imbalanced data), di mana nilai 0 mendominasi dengan 933 observasi dan nilai 1 hanya muncul 67 kali.

### 2.2.4 Univariate Analysis
"""

numerical_features = ['Age', 'CGPA', 'Depression', 'Anxiety', 'PanicAttack', 'SpecialistTreatment', 'SymptomFrequency_Last7Days', 'HasMentalHealthSupport', 'SleepQuality', 'StudyStressLevel', 'StudyHoursPerWeek', 'AcademicEngagement']
categorical_features = ['Gender', 'Course', 'YearOfStudy']

"""#### Fitur kategori

> Fitur Gender
"""

feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
gender = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gender)
count.plot(kind='bar', title=feature);

"""> Fitur course"""

feature = categorical_features[1]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
course = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(course)
count.plot(kind='bar', title=feature, figsize=(25,10))

"""> Fitur years of study"""

feature = categorical_features[2]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
yos = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(yos)
count.plot(kind='bar', title=feature, figsize=(25,10))

"""#### Fitur numerik"""

df.hist(bins=50, figsize=(20, 15))
plt.show()

sakit_mental = df[(df['Depression'] == 1) | (df['Anxiety'] == 1) | (df['PanicAttack'] == 1)]
jumlah_sakit_mental = len(sakit_mental)

sehat_mental = df[(df['Depression'] == 0) & (df['Anxiety'] == 0) & (df['PanicAttack'] == 0)]
jumlah_sehat_mental = len(sehat_mental)

total_mahasiswa = len(df)

print(f"Total mahasiswa        : {total_mahasiswa}")
print(f"Mahasiswa dengan gangguan mental : {jumlah_sakit_mental}")
print(f"Mahasiswa tanpa gangguan mental : {jumlah_sehat_mental}")

"""Hasil analisis : <br>
- Mayoritas responden adalah perempuan, yaitu 76%, sementara laki-laki 24%.
- Program studi terbanyak berasal dari: Engineering, BCS, dan BIT.
- Sebagian besar mahasiswa berasal dari tingkat 1 (412 responden), disusul tingkat 2 (274), tingkat 3 (240), dan tingkat 4 (74).
- Rentang usia responden berkisar antara 18 hingga 25 tahun.
- IPK (GPA) paling banyak berada di kisaran 4.0 dan 2.0.
- Sebagian besar responden tidak mendapatkan perlakuan khusus (special treatment).
- Jumlah mahasiswa yang mengalami depresi, kecemasan (anxiety), dan panic attack seimbang (50:50).
- Mahasiswa umumnya menghabiskan waktu minimal 40 jam per minggu untuk belajar, bahkan ada yang mencapai 70 jam.
- sebanyak 845 dari 1000 data mengalami sakit mental baik depresi, anxiety, dan panick attack.

### 2.2.5 Multivariate Analysis

#### Fitur kategori
"""

plt.figure(figsize=(12,6))
sns.barplot(x='YearOfStudy', y='Depression', hue='Gender', data=df)
plt.title('Prevalensi Depression berdasarkan Tahun Studi dan Gender')
plt.ylabel('Proporsi Depression')
plt.show()

"""Prevalensi depresi bervariasi berdasarkan tahun studi dan gender. Tahun studi 4 menunjukkan prevalensi tertinggi, terutama pada pria, namun dengan ketidakpastian data yang tinggi. Sementara itu, tahun studi 1 dan 2 menunjukkan prevalensi yang lebih seimbang antara gender.

#### Fitur numerik
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Matriks korelasi menunjukkan beberapa hubungan antara fitur numerik. Korelasi positif terkuat terlihat antara 'StudyHoursPerWeek' dan 'CGPA' (0.93), menunjukkan bahwa semakin banyak jam belajar per minggu, IPK cenderung meningkat.

# **3. Data Preparation**
"""

df['MentalHealthScore'] = df['Depression'] + df['Anxiety'] + df['PanicAttack']
df.drop(['Depression', 'Anxiety', 'PanicAttack','Timestamp'], axis=1, inplace=True)

df.head()

"""Menggabungkan tiga indikator kesehatan mental (Depresi, Kecemasan, dan Serangan Panik) menjadi satu skor komposit baru yang disebut 'MentalHealthScore'. Setelah skor baru ini dibuat, kolom-kolom asli yang digunakan untuk membuatnya, ditambah kolom 'Timestamp', dihapus dari data. Hal ini menghasilkan tampilan data yang lebih ringkas, fokus pada skor kesehatan mental agregat."""

plt.figure(figsize=(12, 6))
sns.histplot(data=df, x='MentalHealthScore', kde=True)
plt.title('Distribusi Skor Kesehatan Mental')
plt.show()

"""Grafik ini menunjukkan sebaran nilai skor kesehatan mental. Terlihat ada beberapa kelompok orang dengan skor yang berbeda-beda, yaitu ada banyak orang dengan skor sekitar 1, banyak juga yang skornya sekitar 2, dan beberapa di skor 0 atau 3. Ini menandakan bahwa tingkat kesehatan mental orang tidak sama."""

df_copy = df.copy()

"""## 3.1 Mapping

Dilakukan transformasi nilai string menjadi numerik untuk kolom 'Gender' dan 'YearOfStudy' menggunakan mapping manual. Teknik ini disebut Label Encoding, di mana:
- 'Gender' diubah menjadi binary (Female=0, Male=1)

- 'YearOfStudy' diubah menjadi ordinal (Year 1=1, ..., Year 4=4)
"""

df_copy['Gender'] = df_copy['Gender'].map({'Female': 0, 'Male': 1})
df_copy['YearOfStudy'] = df_copy['YearOfStudy'].map({'year 1': 1, 'year 2': 2, 'year 3': 3, 'year 4': 4},)

"""## 3.2 Split dataset

Dataset dibagi menjadi data training (80%) dan testing (20%) menggunakan train_test_split. Kolom target yang diprediksi adalah MentalHealthScore, sedangkan semua kolom lainnya digunakan sebagai fitur. Parameter random_state=123 diterapkan untuk memastikan pembagian data konsisten dan terdistribusi merata setiap kali kode dijalankan.
"""

X = df_copy.drop(["MentalHealthScore"],axis =1)
y = df_copy["MentalHealthScore"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## 3.3 Frequency Encoding

Pada kolom Course yang memiliki banyak kategori jurusan, digunakan frequency encoding untuk mengubah setiap kategori menjadi nilai numerik berdasarkan frekuensi kemunculannya di data latih. Teknik ini bekerja dengan memetakan setiap jurusan ke probabilitas relatifnya (nilai antara 0 dan 1), sehingga mempertahankan informasi distribusi data tanpa menambah dimensi seperti one-hot encoding
"""

course_freq = X_train['Course'].value_counts(normalize=True)
X_train['Course'] = X_train['Course'].map(course_freq)

X_train['Course'].head()

"""## 3.4 MinMaxScaler

Kolom Age, CGPA, dan StudyHoursPerWeek memiliki nilai numerik yang sangat bervariasi skalanya, sehingga dilakukan normalisasi menggunakan MinMaxScaler untuk membawa semua fitur ke rentang seragam (biasanya 0-1). Hal ini penting agar algoritma machine learning (terutama KNN dan Boosting) tidak bias terhadap fitur dengan skala lebih besar, sehingga semua variabel berkontribusi secara seimbang dalam pelatihan model.
"""

cols_to_scale = ['Age', 'CGPA', 'StudyHoursPerWeek']
scaler = MinMaxScaler()
scaler.fit(X_train[cols_to_scale])
X_train[cols_to_scale] = scaler.transform(X_train[cols_to_scale])
X_train[cols_to_scale].head()

X_train.head()

"""# **4. Modeling**

Dalam studi kasus ini, saya mengunakan model KNN dan Boosting dan melakukan evaluasi pada model d enganm metrik MSE(Mean Squared Error)
"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'aboost'])

"""## 4.1 KNN"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""## 4.2 Boosting Algorithm"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)

models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""# **5**. **Evaluasi Model**

Sebelum evaluasi, kolom `Course` di X_test di-encode menggunakan course_freq (hasil encoding dari data latih) agar konsisten dengan model yang sudah dilatih. lalu kolom `cols_to_scale = Age,CGPA,StudyHoursPerWeek` diskalakan dengan scaler yang sama seperti data latih. Hal ini dilakukan untuk memastikan data uji diproses sama persis seperti data latih, sehingga evaluasi model tetap valid
"""

X_test_proc = X_test.copy()
X_test_proc['Course'] = X_test_proc['Course'].map(course_freq).fillna(0)
X_test_proc[cols_to_scale] = scaler.transform(X_test_proc[cols_to_scale])

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','aboost'])
model_dict = {'KNN': knn, 'aboost': boosting }

for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train)) / 1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test_proc)) / 1e3
print("Model Evaluation (MSE × 10³):")
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3, color=['skyblue', 'purple'])
ax.set_title("Model Comparison Based on MSE (× 10³)")
ax.set_xlabel("MSE")
ax.grid(zorder=0)
plt.show()

"""Berdasarkan hasil evaluasi model, AdaBoost menunjukkan performa yang sedikit lebih baik daripada KNN dengan nilai MSE yang lebih rendah baik pada data latih (train) maupun data uji (test). Kedua model memiliki performa yang sangat baik karena nilai MSE-nya sangat rendah (skala ×10³). Hasil ini juga menunjukkan bahwa kedua model mampu menggeneralisasi dengan baik, terlihat dari selisih MSE train dan test yang kecil."""

prediksi = X_test_proc.iloc[:1].copy()
y_true_sample = y_test.iloc[:1].values[0]

pred_dict = {'y_true': [y_true_sample]}
for name, model in model_dict.items():
    pred_value = model.predict(prediksi)[0]
    pred_dict[f'prediksi_{name}'] = [round(pred_value, 1)]

pd.DataFrame(pred_dict)

"""Model KNN menilai tingkat mentalscore mahasiswa sebesar 1.1, sedangkan model Boosting  memprediksi mentalscore sebesar 1.5. Berdasarkan hasil prediksi ini KNN terlihat ungul dibandingkan model boosting karena nilai KNN lebih mendekati dari nilai yang sebenarnya yaitu 1.


*Walaupun pada evaluasi metrik MSE algortima boosting terlihat unggul, namun perbedaan eror mereka tidak terlalu jauh hanya sebesar 0.00002–0.00003, sehingga dalam praktik, prediksi keduanya bisa terlihat sama-sama akurat atau bahkan KNN sedikit lebih mendekati nilai sebenarnya*
"""

feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': boosting.feature_importances_
}).sort_values('Importance', ascending=False)

plt.figure(figsize=(15, 5))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('Faktor-faktor yang Memengaruhi Kesehatan Mental Mahasiswa', fontsize=15)
plt.xlabel('Tingkat Kepentingan')
plt.tight_layout()
plt.show()

"""Berdasarkan grafik diatas dapat diketahui bahwa nilai GPA dan durasi mahasiswa belajar dalam semingu memiliki pengaruh yang sangat penting terhadap kesehatan mental mahasiswa"""